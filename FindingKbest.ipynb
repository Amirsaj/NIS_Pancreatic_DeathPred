{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76ed359-dc87-4555-bd00-c9cfb5e5e9a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "# import Libraries \n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score,recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "from sklearn.feature_selection import SelectKBest , f_regression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import datasets, ensemble\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import max_error,mean_squared_error,mean_absolute_error,mean_squared_log_error,r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "# from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X = pd.read_csv('X_Cleared_Balance1.5.csv')  \n",
    "Y = pd.read_csv('Y_Cleared_Balance1.5.csv')\n",
    "y1 = Y['0']\n",
    "xe = X\n",
    "xe = xe.drop(['Unnamed: 0'], axis=1)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "for i in xe.columns:\n",
    "    if i == 'age':\n",
    "        continue\n",
    "    xe[i] = xe[i].astype('category')\n",
    "    \n",
    "y1 = y1.astype('category')\n",
    "\n",
    "# Define the range of K values to test\n",
    "k_values = [5, 10]\n",
    "k_values = list(range(1,xe.shape[1]))\n",
    "\n",
    "\n",
    "# Define the machine learning models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": SGDClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "    'RidgeClassifierCV':RidgeClassifierCV(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier':ensemble.GradientBoostingClassifier(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'MLPClassifier':MLPClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop over each model and each K value and train the model\n",
    "for model_name, model in models.items():\n",
    "    model_results = []\n",
    "    for k in k_values:\n",
    "        # Use the SelectKBest function to select the top K features based on ANOVA F-value\n",
    "        # f_classif\n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        X_kbest = selector.fit_transform(xe, y1)\n",
    "        \n",
    "        # Evaluate the model using cross-validation\n",
    "        scores = cross_val_score(model, X_kbest, y1, cv=5)\n",
    "        avg_score = scores.mean()\n",
    "        \n",
    "        # Append the average score to the list of results for this model\n",
    "        model_results.append(avg_score)\n",
    "    \n",
    "    # Store the results for this model in the dictionary\n",
    "    results[model_name] = model_results\n",
    "\n",
    "# Print the results for each model\n",
    "import sys\n",
    "\n",
    "# Open a file to write the prints\n",
    "stringres = ''\n",
    "print('res')\n",
    "with open('output.txt', 'w') as f:\n",
    "    # Redirect the output to the file\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        print(model_name)\n",
    "        stringres = stringres + 'Model_Name : '+model_name\n",
    "        bestScore = -float('inf')\n",
    "        bestK = 0\n",
    "        for k, score in zip(k_values, model_results):\n",
    "            print(f\"K = {k}: score = {score:.3f}\")\n",
    "            if bestScore<score:\n",
    "                bestScore = score\n",
    "                bestK = k\n",
    "        stringres = stringres+' | K : '+ str(bestK)+' | Score : '+str(bestScore)+'\\n'\n",
    "    sys.stdout = sys.__stdout__\n",
    "with open('LastRes.txt', 'w') as text_file:\n",
    "    text_file.write(stringres)\n",
    "# print(stringres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b75ed-c17e-4730-9252-94f9a2b30bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.read_csv('/raid-18/CHS/jakeluo/share/notebook/ataleban@uwm.edu/Panc_/X_Cleared_Balance1.5.csv')  \n",
    "Y = pd.read_csv('/raid-18/CHS/jakeluo/share/notebook/ataleban@uwm.edu/Panc_/Y_Cleared_Balance1.5.csv')\n",
    "y1 = Y['0']\n",
    "xe = X\n",
    "xe = xe.drop(['Unnamed: 0'], axis=1)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "for i in xe.columns:\n",
    "    if i == 'age':\n",
    "        continue\n",
    "    xe[i] = xe[i].astype('category')\n",
    "    \n",
    "y1 = y1.astype('category')\n",
    "\n",
    "# Define the range of K values to test\n",
    "k_values = [5, 10]\n",
    "k_values = list(range(1,xe.shape[1]))\n",
    "\n",
    "\n",
    "# Define the machine learning models to test\n",
    "models = {\n",
    "    \"Logistic Regression\": SGDClassifier(),\n",
    "    'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "    'RidgeClassifierCV':RidgeClassifierCV(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier':ensemble.GradientBoostingClassifier(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'MLPClassifier':MLPClassifier()\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Loop over each model and each K value and train the model\n",
    "for model_name, model in models.items():\n",
    "    model_results = []\n",
    "    for k in k_values:\n",
    "        # Use the SelectKBest function to select the top K features based on ANOVA F-value\n",
    "        # f_classif\n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        X_kbest = selector.fit_transform(xe, y1)\n",
    "        \n",
    "        # Evaluate the model using cross-validation\n",
    "        scores = cross_val_score(model, X_kbest, y1, cv=5)\n",
    "        avg_score = scores.mean()\n",
    "        \n",
    "        # Append the average score to the list of results for this model\n",
    "        model_results.append(avg_score)\n",
    "    \n",
    "    # Store the results for this model in the dictionary\n",
    "    results[model_name] = model_results\n",
    "\n",
    "# Print the results for each model\n",
    "import sys\n",
    "\n",
    "# Open a file to write the prints\n",
    "stringres = ''\n",
    "print('res')\n",
    "with open('output.txt', 'w') as f:\n",
    "    # Redirect the output to the file\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for model_name, model_results in results.items():\n",
    "        print(model_name)\n",
    "        stringres = stringres + 'Model_Name : '+model_name\n",
    "        bestScore = -float('inf')\n",
    "        bestK = 0\n",
    "        for k, score in zip(k_values, model_results):\n",
    "            print(f\"K = {k}: score = {score:.3f}\")\n",
    "            if bestScore<score:\n",
    "                bestScore = score\n",
    "                bestK = k\n",
    "        stringres = stringres+' | K : '+ str(bestK)+' | Score : '+str(bestScore)+'\\n'\n",
    "    sys.stdout = sys.__stdout__\n",
    "with open('LastRes.txt', 'w') as text_file:\n",
    "    text_file.write(stringres)\n",
    "# print(stringres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a13ab-7e52-44a3-85c8-5f5a3492f71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05cdf5-66a4-4420-9be2-2e8ef441de47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NIS",
   "language": "python",
   "name": "nis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
